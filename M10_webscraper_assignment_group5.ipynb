{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36b58323",
   "metadata": {},
   "source": [
    "## Module 10 Assignment - Scraping a Website\n",
    "* Author: brandon chiazza\n",
    "* version 2.0\n",
    "\n",
    "We will be creating a web scraper to parse a table from the Charities Bureau Website. From the website: “All \n",
    "charitable organizations operating in New York State are required by law to register and file annual financial reports \n",
    "with the Attorney General's Office. This includes any organization that conducts charitable activities, holds property \n",
    "that is used for charitable purposes, or solicits financial or other contributions.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a378dd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Forever Captain Poodaman\" The Ahmad Butler Fo...</td>\n",
       "      <td>48-07-16</td>\n",
       "      <td>843800926</td>\n",
       "      <td>NFP</td>\n",
       "      <td>PHILADELPHIA</td>\n",
       "      <td>PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Incredibly Blessed\" Inc</td>\n",
       "      <td>49-54-61</td>\n",
       "      <td>842071758</td>\n",
       "      <td>NFP</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"R\" S.U.C.C.E.S.S. Foundation Inc.</td>\n",
       "      <td>49-06-59</td>\n",
       "      <td>874012670</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Studio 5404\" Inc.</td>\n",
       "      <td>44-39-58</td>\n",
       "      <td>463180470</td>\n",
       "      <td>NFP</td>\n",
       "      <td>MASSAPAQUA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>04/11 10:17 PM test</td>\n",
       "      <td>47-13-95</td>\n",
       "      <td>206256427</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1/20/21 Action Fund</td>\n",
       "      <td>46-99-13</td>\n",
       "      <td>832210730</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>10/40 Connections, Inc.</td>\n",
       "      <td>45-70-15</td>\n",
       "      <td>621825230</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HIXSON</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1000 Feet Project, Inc</td>\n",
       "      <td>45-00-14</td>\n",
       "      <td>473820859</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1000 Islands Hose Haulers</td>\n",
       "      <td>45-38-38</td>\n",
       "      <td>454570241</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARTHAGE</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Organization Name  NY Reg #        EIN  \\\n",
       "0                                                 None      None       None   \n",
       "1    \"Forever Captain Poodaman\" The Ahmad Butler Fo...  48-07-16  843800926   \n",
       "2                             \"Incredibly Blessed\" Inc  49-54-61  842071758   \n",
       "3                   \"R\" S.U.C.C.E.S.S. Foundation Inc.  49-06-59  874012670   \n",
       "4                                   \"Studio 5404\" Inc.  44-39-58  463180470   \n",
       "..                                                 ...       ...        ...   \n",
       "107                                04/11 10:17 PM test  47-13-95  206256427   \n",
       "108                                1/20/21 Action Fund  46-99-13  832210730   \n",
       "109                            10/40 Connections, Inc.  45-70-15  621825230   \n",
       "110                             1000 Feet Project, Inc  45-00-14  473820859   \n",
       "111                          1000 Islands Hose Haulers  45-38-38  454570241   \n",
       "\n",
       "    Registrant Type           City State  \n",
       "0              None           None  None  \n",
       "1               NFP   PHILADELPHIA    PA  \n",
       "2               NFP  STATEN ISLAND    NY  \n",
       "3               NFP      ROCHESTER    NY  \n",
       "4               NFP     MASSAPAQUA    NY  \n",
       "..              ...            ...   ...  \n",
       "107             NFP         ALBANY    NY  \n",
       "108             NFP  SAN FRANCISCO    CA  \n",
       "109             NFP         HIXSON    TN  \n",
       "110             NFP       NEW YORK    NY  \n",
       "111             NFP       CARTHAGE    NY  \n",
       "\n",
       "[112 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###Load modules\n",
    "#!pip install webdriver-manager\n",
    "#!pip install awscli\n",
    "import awscli\n",
    "import boto3\n",
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "s=Service(ChromeDriverManager().install())\n",
    "browser = webdriver.Chrome(service=s)\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]') #identifies the location of the EIN element\n",
    "inputElement.send_keys('0') #sends the \"0\" as the search value for EIN \n",
    "inputElement1 = browser.find_element(By.XPATH,'//*[@id=\"header\"]/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]').click() #instatiates the click of the search\n",
    "sleep(4) #allow for the page to load by adding a sleep element\n",
    "#identify the table to scrape\n",
    "table = browser.find_element(By.CSS_SELECTOR,'table.Bordered')\n",
    "sleep(1)\n",
    "#####CREATE DATE FRAME#####\n",
    "#create empty dataframe\n",
    "df =[]\n",
    "\n",
    "#loop through dataframe to export table\n",
    "\n",
    "pages = range(1, 8)  \n",
    "\n",
    "page = browser.find_element(By.XPATH,'/html/body/div[2]/div/table/tbody/tr/td[3]/div/div/span[2]/a[1]')\n",
    "\n",
    "for i in pages: \n",
    "      page = browser.find_element(By.XPATH,'/html/body/div[2]/div/table/tbody/tr/td[3]/div/div/span[2]/a[1]')\n",
    "      for row in table.find_elements(By.CSS_SELECTOR,'tr'):\n",
    "            cols = df.append([cell.text for cell in row.find_elements(By.CSS_SELECTOR,'td')])\n",
    "\n",
    "\n",
    "#update dataframe with header \n",
    "df = pd.DataFrame(df, columns = [\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"])\n",
    "display(df) #let's have a look at the data before creating the CSV file and loading it into s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81db30e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded file to location: s3://m10-webscrape-group5/charities_bureau_scrape_group5_20240414210340.csv\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Set up your AWS credentials\n",
    "aws_access_key_id = 'AKIAVTUKVQ4PLLEYQHV6'\n",
    "aws_secret_access_key = 'ZHaHU2mf/XWGCkI6rFz8p8H4D+BJ8W8VDXhhDe7E'\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "\n",
    "# Prepare CSV file\n",
    "pathname = 'm10-webscrape-group5'  # Specify location of s3:/{my-bucket}/\n",
    "filename = 'charities_bureau_scrape_group5'  # Name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\")  # Timestamp\n",
    "s3_file_path = f\"{filename}_{datetime}.csv\"  # Name of the filepath and CSV file\n",
    "\n",
    "# Convert DataFrame to CSV string\n",
    "csv_buffer = StringIO()\n",
    "df.to_csv(csv_buffer, index=False)\n",
    "csv_buffer.seek(0)\n",
    "\n",
    "# Upload the file to S3\n",
    "s3.put_object(Bucket=pathname, Key=s3_file_path, Body=csv_buffer.getvalue())\n",
    "\n",
    "# Print success message\n",
    "print(\"Successfully uploaded file to location:\", f\"s3://{pathname}/{s3_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb7934",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://www.programiz.com/python-programming/working-csv-files\n",
    "* https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_bucket\n",
    "* https://realpython.com/python-boto3-aws-s3/\n",
    "* https://robertorocha.info/setting-up-a-selenium-web-scraper-on-aws-lambda-with-python/ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
